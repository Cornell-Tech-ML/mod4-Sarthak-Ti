{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first the question is to see what the output should be\n",
    "# the idea is we tile it properly so that we can simply do max reduction or whatever for pooling. so you could do a loop with a kernel, but that's not optimal\n",
    "# let's test pytorch unfold function\n",
    "\n",
    "import torch\n",
    "\n",
    "I = torch.arange(16).reshape(1, 1, 4, 4).float()\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 1, kernel_size=(2, 2), stride=(2, 2), bias=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so the easy way to do this is just directly run a kernel over it, so do a convolution with a kernel of size 2x2 and stride 2\n",
    "m = torch.nn.Conv2d(1, 1, 2, 2, 0, bias=False)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "tensor([[[ 0.,  1.,  4.,  5.],\n",
      "         [ 1.,  2.,  5.,  6.]],\n",
      "\n",
      "        [[ 4.,  5.,  8.,  9.],\n",
      "         [ 5.,  6.,  9., 10.]]])\n"
     ]
    }
   ],
   "source": [
    "# let's define a function that takes in a tensor and a kernel size and manually does this\n",
    "# I will just be 4x4 or whatever\n",
    "def tile(I, kernel_size):\n",
    "    out = torch.zeros(\n",
    "        I.shape[0] // kernel_size[0],\n",
    "        I.shape[1] // kernel_size[1],\n",
    "        kernel_size[0] * kernel_size[1],\n",
    "    )\n",
    "    i_steps = I.shape[0] // kernel_size[0]\n",
    "    j_steps = I.shape[0] // kernel_size[1]\n",
    "    for i in range(i_steps):\n",
    "        for j in range(j_steps):\n",
    "            out[i, j] = I[i : i + kernel_size[0], j : j + kernel_size[1]].flatten()\n",
    "    return out\n",
    "\n",
    "\n",
    "I = torch.arange(16).reshape(4, 4).float()\n",
    "print(I)\n",
    "out = tile(I, (2, 2))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [4., 5.]])\n",
      "tensor([[1., 2.],\n",
      "        [5., 6.]])\n",
      "tensor([[4., 5.],\n",
      "        [8., 9.]])\n",
      "tensor([[ 5.,  6.],\n",
      "        [ 9., 10.]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(\n",
    "        out[:, :, i]\n",
    "    )  # want to shape it like this, basically like ran the 2d kernel over it... now how to reshape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.],\n",
      "         [ 1.],\n",
      "         [ 2.],\n",
      "         [ 3.]],\n",
      "\n",
      "        [[ 4.],\n",
      "         [ 5.],\n",
      "         [ 6.],\n",
      "         [ 7.]],\n",
      "\n",
      "        [[ 8.],\n",
      "         [ 9.],\n",
      "         [10.],\n",
      "         [11.]],\n",
      "\n",
      "        [[12.],\n",
      "         [13.],\n",
      "         [14.],\n",
      "         [15.]]]) torch.Size([4, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# ok so the way it should stack it is like this, let's make sure my function works\n",
    "out = tile(I, (1, 1))\n",
    "print(out, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  4.,  5.],\n",
       "         [ 2.,  3.,  6.,  7.]],\n",
       "\n",
       "        [[ 8.,  9., 12., 13.],\n",
       "         [10., 11., 14., 15.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if any pool with kernel size of 1, it won't do shit obviously!, so in this case makes it 4x4x1. So this tiling is correct\n",
    "# now the question is hwo to reshape with this\n",
    "\n",
    "# so this is what chatgpt says\n",
    "I2 = I.reshape(2, 2, 2, 2)  # new height, kh, new width, kw\n",
    "print(I2.shape)\n",
    "I3 = I2.permute(0, 2, 1, 3).reshape(2, 2, 4)\n",
    "I3  # new height, new width, kw*kh\n",
    "# I3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tile(I, (2, 2))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  0.,  0.,  0.],\n",
       "         [-1., -1., -1., -1.]],\n",
       "\n",
       "        [[-4., -4., -4., -4.],\n",
       "         [-5., -5., -5., -5.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out - I3  # yeah definitely not the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  2.],\n",
      "        [ 8., 10.]])\n",
      "tensor([[ 1.,  3.],\n",
      "        [ 9., 11.]])\n",
      "tensor([[ 4.,  6.],\n",
      "        [12., 14.]])\n",
      "tensor([[ 5.,  7.],\n",
      "        [13., 15.]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(I3[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23],\n",
      "        [24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35]])\n"
     ]
    }
   ],
   "source": [
    "# let's see the thing for a more complex tensor, 6x6 tensor but tile 3x3\n",
    "I = torch.arange(36).reshape(6, 6)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2, 3]) tensor([[[[ 0,  1,  2],\n",
      "          [ 3,  4,  5]],\n",
      "\n",
      "         [[ 6,  7,  8],\n",
      "          [ 9, 10, 11]],\n",
      "\n",
      "         [[12, 13, 14],\n",
      "          [15, 16, 17]]],\n",
      "\n",
      "\n",
      "        [[[18, 19, 20],\n",
      "          [21, 22, 23]],\n",
      "\n",
      "         [[24, 25, 26],\n",
      "          [27, 28, 29]],\n",
      "\n",
      "         [[30, 31, 32],\n",
      "          [33, 34, 35]]]])\n",
      "torch.Size([2, 2, 9]) tensor([[[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
      "         [ 3,  4,  5,  9, 10, 11, 15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20, 24, 25, 26, 30, 31, 32],\n",
      "         [21, 22, 23, 27, 28, 29, 33, 34, 35]]])\n"
     ]
    }
   ],
   "source": [
    "kh, kw = 3, 3\n",
    "new_height = I.shape[0] // kh\n",
    "new_width = I.shape[1] // kw\n",
    "\n",
    "I2 = I.reshape(new_height, kh, new_width, kw)\n",
    "print(I2.shape, I2)\n",
    "I3 = I2.permute(0, 2, 1, 3).reshape(new_height, new_width, kh * kw)\n",
    "\n",
    "print(I3.shape, I3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 9]) tensor([[[ 0.,  1.,  2.,  6.,  7.,  8., 12., 13., 14.],\n",
      "         [ 1.,  2.,  3.,  7.,  8.,  9., 13., 14., 15.]],\n",
      "\n",
      "        [[ 6.,  7.,  8., 12., 13., 14., 18., 19., 20.],\n",
      "         [ 7.,  8.,  9., 13., 14., 15., 19., 20., 21.]]])\n"
     ]
    }
   ],
   "source": [
    "# so the shape of this is indeed correct, let's test to see if it makes sense\n",
    "out = tile(I, (3, 3))\n",
    "print(out.shape, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "         [ -2.,  -2.,  -2.,  -2.,  -2.,  -2.,  -2.,  -2.,  -2.]],\n",
       "\n",
       "        [[-12., -12., -12., -12., -12., -12., -12., -12., -12.],\n",
       "         [-14., -14., -14., -14., -14., -14., -14., -14., -14.]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wait how to interpret this 2,2,9. Basically 9 2x2 things, so after reduce each of these left with 9 elements...\n",
    "# wtf is this tho? Should have 4 values actually after the reduction, so reduce along this last dimension\n",
    "# the 9 is how many elements are in each of the kernels! So what matters is that we sum along that third dimension is identical, or that the values in each of the 4 are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 63.,  72.],\n",
      "        [117., 126.]])\n",
      "tensor([[ 63,  90],\n",
      "        [225, 252]])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    out.sum(2), I3.sum(2), sep=\"\\n\"\n",
    ")  # the values don't even add up, this is kinda weird?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's manually verify\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 90\n"
     ]
    }
   ],
   "source": [
    "a1 = 0 + 1 + 2 + 6 + 7 + 8 + 12 + 13 + 14\n",
    "a2 = 3 + 4 + 5 + 9 + 10 + 11 + 15 + 16 + 17\n",
    "print(a1, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yeah it seems my out is wrong, let's just go with what they have lol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
